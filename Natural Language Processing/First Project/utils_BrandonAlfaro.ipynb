{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Class TFIDF:**\n","\n","Firstly, the class was initialized with essential attributes such as *corpus, num_documents, vocab, and term_idf_cache*. These attributes were crucial for storing the input documents, keeping track of the number of documents, maintaining the vocabulary set, and caching IDF values to avoid redundant computations.\n","\n","Next, **methods** were implemented to calculate the Term Frequency (TF) and Inverse Document Frequency (IDF) for each term in the corpus. The TF calculation involved counting term occurrences in each document and normalizing by the total number of words. On the other hand, IDF was computed using the logarithmic formula, considering the number of documents containing each term.\n","\n","Subsequently, the **fit method** was developed to fit the TF-IDF model on the corpus. During this step, the vocabulary set was constructed by iterating over each document, updating the set with unique terms, and computing document frequencies for each term.\n","\n","Following the fitting of the model, the **transform method** was created to transform a set of documents into TF-IDF representation. This process involved iterating over each document and term, computing the TF-IDF score by multiplying the TF with IDF, and constructing a sparse TF-IDF matrix using the csr_matrix from SciPy.\n","\n","Finally, **text preprocessing** steps, including tokenization, removal of stopwords, and lemmatization, were incorporated into the split method. The tokenization pattern ensured tokenizing the text into words while excluding single-character words. Regular expressions and NLTK functionalities were utilized for efficient text processing, ensuring that the input text was properly preprocessed before TF-IDF computation.\n"],"metadata":{"id":"ISNdw8xXfS_y"}},{"cell_type":"markdown","source":["**cast_list_as_strings function**:\n","\n","Return a list of strings. Function defined by professor."],"metadata":{"id":"iReg3HzjfpeT"}},{"cell_type":"markdown","source":["**perform_grid_search** function:\n","\n","Performs the grid search and returns the best score and best parameters for Logistic Regression."],"metadata":{"id":"sgJuGm-lb9xw"}},{"cell_type":"markdown","source":["**plot_roc_curve_and_threshold** function:\n","\n","This function plot_roc_curve_and_threshold takes in TF-IDF data, true labels, and a classifier. It can optionally calculate and plot the ROC curve, and if requested, find and print the optimal threshold.\n","\n","It calculates the ROC AUC score if calculate_roc is set to True.\n","If calculate_optimal_threshold is True and no optimal threshold is provided, it determines the threshold that maximizes the sum of true positive rate (TPR) and true negative rate (TNR) from the ROC curve.\n","It plots the ROC curve with thresholds as gradient color if requested.\n","If an optimal threshold is found or provided, it applies the custom threshold to obtain binary predictions.\n","It calculates and prints the classification report, including metrics like accuracy, precision, recall, and F1-score.\n","Finally, it returns a dictionary containing accuracy, precision, recall, F1-score, and a single value for the optimal threshold (if applicable)."],"metadata":{"id":"96B_Ub1f65j4"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sm8pcAQA71NE"},"outputs":[],"source":["import math\n","import numpy as np\n","from scipy.sparse import csr_matrix\n","import re\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","\n","def cast_list_as_strings(mylist):\n","    \"\"\"\n","    return a list of strings\n","    \"\"\"\n","    mylist_of_strings = []\n","    for x in mylist:\n","        mylist_of_strings.append(str(x))\n","\n","    return mylist_of_strings\n","\n","class TFIDF:\n","    def __init__(self):\n","        self.corpus = None\n","        self.num_documents = None\n","        self.vocab = None\n","        self.term_idf_cache = {}\n","        self.tfidf_scores = None\n","        self.stopwords = set(stopwords.words('english'))\n","        self.lemmatizer = WordNetLemmatizer()\n","\n","    def calculate_tf(self, term, document):\n","        word_count = document.count(term)\n","        total_words = len(self.split(document))\n","        return word_count / total_words if total_words > 0 else 0\n","\n","    def calculate_idf(self, term):\n","        if term in self.term_idf_cache:\n","            return self.term_idf_cache[term]\n","\n","        num_documents_with_term = self.doc_freq.get(term, 0)\n","        idf = math.log(self.num_documents / (1 + num_documents_with_term))\n","        self.term_idf_cache[term] = idf\n","        return idf\n","\n","    def fit(self, corpus):\n","        self.corpus = corpus\n","        self.num_documents = len(corpus)\n","        self.vocab = set()  # Initialize vocabulary set\n","        self.doc_freq = {}  # Dictionary to store document frequency for each term \\ number of documents containing term t\n","\n","        # Construct vocabulary set and compute document frequency \\ number of documents containing term t\n","        for document in self.corpus:\n","            terms = self.split(document)\n","            self.vocab.update(terms)\n","            for term in set(terms):  # Use set to count each document only once\n","                if term not in self.stopwords: # Exclude stopwords from vocabulary\n","                    self.doc_freq[term] = self.doc_freq.get(term, 0) + 1\n","\n","        # Precompute term indices\n","        self.term_indices = {term: idx for idx, term in enumerate(self.vocab)}\n","\n","    def transform(self, questions):\n","        tfidf_data = []\n","        tfidf_row = []\n","        tfidf_col = []\n","\n","        # Iterate over documents and terms to compute TF-IDF scores\n","        for i, document in enumerate(questions):\n","            for term in set(self.split(document)):\n","                if term in self.vocab:  # Check if term exists in vocabulary, if not we will just work with tokens from seen during fit\n","                    if term not in self.term_idf_cache:\n","                        self.term_idf_cache[term] = self.calculate_idf(term)\n","\n","                    tfidf_score = self.calculate_tf(term, document) * self.term_idf_cache[term]\n","                    tfidf_data.append(tfidf_score)\n","                    tfidf_row.append(i)\n","                    tfidf_col.append(self.term_indices[term])\n","\n","        self.tfidf_scores = csr_matrix((tfidf_data, (tfidf_row, tfidf_col)), shape=(len(questions), len(self.vocab)))\n","\n","        return self.tfidf_scores\n","\n","    def split(self, text, token_pattern=\"\\\\b\\\\w\\\\w+\\\\b\"):\n","        # Split text into terms using the provided token pattern\n","        terms = re.findall(token_pattern, text.lower())\n","        lemmatized_terms = [self.lemmatizer.lemmatize(term) for term in terms]\n","        return [term for term in lemmatized_terms if term not in self.stopwords]  # Exclude stopwords after lemmatization\n","\n","def perform_grid_search(X_train, y_train, X_val, y_val, param_grid):\n","    # Initialize Logistic Regression model\n","    log_reg = sklearn.linear_model.LogisticRegression(random_state=123, max_iter=100000)\n","\n","    # Perform grid search\n","    best_score = 0\n","    best_params = None\n","    for C in param_grid['C']:\n","        for solver in param_grid['solver']:\n","            for penalty in param_grid['penalty']:\n","                log_reg.set_params(C=C, solver=solver, penalty=penalty)\n","                log_reg.fit(X_train, y_train)\n","                score = log_reg.score(X_val, y_val)\n","\n","                # Check if this is the best score\n","                if score > best_score:\n","                    best_score = score\n","                    best_params = {'C': C, 'solver': solver, 'penalty': penalty}\n","\n","    return best_score, best_params\n","\n","def plot_roc_curve_and_threshold(tfidf_data, y_true, clf, optimal_threshold=None, calculate_roc=True, calculate_optimal_threshold=False):\n","\n","    results = {}\n","    # Extract probabilities for the positive class\n","    y_score = clf.predict_proba(tfidf_data)[:, 1]\n","\n","    roc_auc_score = None\n","    accuracy = None\n","    precision = None\n","    recall = None\n","    f1_score = None\n","\n","    # Calculate ROC AUC score if requested\n","    if calculate_roc:\n","        roc_auc_score = sklearn.metrics.roc_auc_score(y_true, y_score)\n","        print(\"ROC AUC score:\", roc_auc_score)\n","\n","        # Generate ROC curve if requested\n","        fpr, tpr, thresholds = sklearn.metrics.roc_curve(y_true, y_score)\n","        thresholds_clipped = np.clip(thresholds, 0, 1)\n","\n","        # Plot ROC curve with thresholds as gradient color\n","        plt.figure()\n","        plt.scatter(fpr, tpr, c=thresholds_clipped, cmap='viridis', s=5)\n","        plt.colorbar(label='Threshold')\n","        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random classifier')\n","        plt.xlim([0.0, 1.0])\n","        plt.ylim([0.0, 1.05])\n","        plt.xlabel('False Positive Rate')\n","        plt.ylabel('True Positive Rate')\n","        plt.title('ROC Curve with Thresholds')\n","        plt.legend(loc=\"lower right\")\n","        plt.show()\n","\n","    # Print the optimal threshold if provided\n","    if calculate_optimal_threshold:\n","        if optimal_threshold is None:\n","            optimal_idx = np.argmax(tpr - fpr)\n","            optimal_threshold = thresholds_clipped[optimal_idx]\n","            print(\"Optimal Threshold:\", optimal_threshold)\n","\n","    # Apply custom threshold to obtain binary predictions and calculate classification report\n","    if optimal_threshold is not None:\n","        y_pred_custom = (y_score >= optimal_threshold).astype(int)\n","\n","        # Calculate classification report\n","        print(sklearn.metrics.classification_report(y_true, y_pred_custom))\n","        report = sklearn.metrics.classification_report(y_true, y_pred_custom, output_dict=True)\n","\n","        # Extract relevant metrics from the classification report\n","        accuracy = report['accuracy']\n","        precision = report['macro avg']['precision']\n","        recall = report['macro avg']['recall']\n","        f1_score = report['macro avg']['f1-score']\n","\n","        results = {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-score': f1_score}\n","\n","    # Return the metrics and optimal threshold\n","    return optimal_threshold, results"]}]}