{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":71526,"databundleVersionId":7821276,"sourceType":"competition"}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-31T16:22:23.791693Z","iopub.execute_input":"2024-03-31T16:22:23.792410Z","iopub.status.idle":"2024-03-31T16:22:25.704433Z","shell.execute_reply.started":"2024-03-31T16:22:23.792361Z","shell.execute_reply":"2024-03-31T16:22:25.702828Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/recsysmasterfds-2024/train.csv\n/kaggle/input/recsysmasterfds-2024/kaggle_baseline.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Let us first do some preprocessing","metadata":{}},{"cell_type":"code","source":"# Remove warnings\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n# Read the input csv and rename the columns\n\ntrain = pd.read_csv('/kaggle/input/recsysmasterfds-2024/train.csv')\ntrain.rename(columns={'release_date':'genre', 'sex':'age', 'age':'sex'}, inplace=True) \ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-31T16:22:25.706673Z","iopub.execute_input":"2024-03-31T16:22:25.707913Z","iopub.status.idle":"2024-03-31T16:22:27.419444Z","shell.execute_reply.started":"2024-03-31T16:22:25.707859Z","shell.execute_reply":"2024-03-31T16:22:27.418223Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   user_id                title  movie_id  rating                genre  age  \\\n0     2592       Top Gun (1986)      1101       4       Action|Romance   50   \n1     4318  12 Angry Men (1957)      1203       4                Drama   25   \n2     2756     Robocop 2 (1990)      2986       2  Action|Crime|Sci-Fi   18   \n3     1706  Modern Times (1936)      3462       5               Comedy   25   \n4     4813    Milk Money (1994)       276       3       Comedy|Romance   35   \n\n  sex  \n0   M  \n1   M  \n2   M  \n3   M  \n4   F  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>title</th>\n      <th>movie_id</th>\n      <th>rating</th>\n      <th>genre</th>\n      <th>age</th>\n      <th>sex</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2592</td>\n      <td>Top Gun (1986)</td>\n      <td>1101</td>\n      <td>4</td>\n      <td>Action|Romance</td>\n      <td>50</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4318</td>\n      <td>12 Angry Men (1957)</td>\n      <td>1203</td>\n      <td>4</td>\n      <td>Drama</td>\n      <td>25</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2756</td>\n      <td>Robocop 2 (1990)</td>\n      <td>2986</td>\n      <td>2</td>\n      <td>Action|Crime|Sci-Fi</td>\n      <td>18</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1706</td>\n      <td>Modern Times (1936)</td>\n      <td>3462</td>\n      <td>5</td>\n      <td>Comedy</td>\n      <td>25</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4813</td>\n      <td>Milk Money (1994)</td>\n      <td>276</td>\n      <td>3</td>\n      <td>Comedy|Romance</td>\n      <td>35</td>\n      <td>F</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"We tried two different approaches to make predictions, the first one is to simply use the ratings of the DataFrame, the other one is to filter to take only the top 15% of samples for each user. We tried both approaches and the ratings approaches worked better. However, we decided to include the top 15% filtering to state constancy.","metadata":{}},{"cell_type":"code","source":"# Calculate the threshold rating for each user_id\n\nthreshold_ratings = train.groupby('user_id')['rating'].quantile(0.85)\nthreshold_int = threshold_ratings.astype(int)\ndelta = (threshold_ratings - threshold_int) > 1e-5\n\n\n# Update the threshold ratings to be integers\n\nfor i in threshold_ratings.index:\n    if delta[i] == True:\n        threshold_ratings[i] = int(threshold_ratings[i]) + 1\n        \n        \n# Function to filter ratings for each user\n\ndef retain_top_ratings(group):\n    threshold = threshold_ratings[group.name]\n    return group[group['rating'] >= threshold]\n\n\n# Apply the filtering function to retain top 85% ratings for each user\n\ntop_ratings_df = train.groupby('user_id').apply(retain_top_ratings).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T16:22:27.420731Z","iopub.execute_input":"2024-03-31T16:22:27.421086Z","iopub.status.idle":"2024-03-31T16:22:32.659876Z","shell.execute_reply.started":"2024-03-31T16:22:27.421046Z","shell.execute_reply":"2024-03-31T16:22:32.658690Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Now we process the columns to match the factorization machine format.","metadata":{}},{"cell_type":"code","source":"# Obtain the release date of each movie\n\ntrain['release_date'] = train['title'].str[-6:].str[1:5].astype(int)\n\n\n# Mapping dictionary\n\nclass_mapping = {'M': 1, 'F': 0}\n\n\n# Convert class_column to binary values\n\ntrain['sex'] = train['sex'].map(class_mapping)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-31T16:22:32.663630Z","iopub.execute_input":"2024-03-31T16:22:32.664157Z","iopub.status.idle":"2024-03-31T16:22:33.251389Z","shell.execute_reply.started":"2024-03-31T16:22:32.664091Z","shell.execute_reply":"2024-03-31T16:22:33.250062Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   user_id                title  movie_id  rating                genre  age  \\\n0     2592       Top Gun (1986)      1101       4       Action|Romance   50   \n1     4318  12 Angry Men (1957)      1203       4                Drama   25   \n2     2756     Robocop 2 (1990)      2986       2  Action|Crime|Sci-Fi   18   \n3     1706  Modern Times (1936)      3462       5               Comedy   25   \n4     4813    Milk Money (1994)       276       3       Comedy|Romance   35   \n\n   sex  release_date  \n0    1          1986  \n1    1          1957  \n2    1          1990  \n3    1          1936  \n4    0          1994  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>title</th>\n      <th>movie_id</th>\n      <th>rating</th>\n      <th>genre</th>\n      <th>age</th>\n      <th>sex</th>\n      <th>release_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2592</td>\n      <td>Top Gun (1986)</td>\n      <td>1101</td>\n      <td>4</td>\n      <td>Action|Romance</td>\n      <td>50</td>\n      <td>1</td>\n      <td>1986</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4318</td>\n      <td>12 Angry Men (1957)</td>\n      <td>1203</td>\n      <td>4</td>\n      <td>Drama</td>\n      <td>25</td>\n      <td>1</td>\n      <td>1957</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2756</td>\n      <td>Robocop 2 (1990)</td>\n      <td>2986</td>\n      <td>2</td>\n      <td>Action|Crime|Sci-Fi</td>\n      <td>18</td>\n      <td>1</td>\n      <td>1990</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1706</td>\n      <td>Modern Times (1936)</td>\n      <td>3462</td>\n      <td>5</td>\n      <td>Comedy</td>\n      <td>25</td>\n      <td>1</td>\n      <td>1936</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4813</td>\n      <td>Milk Money (1994)</td>\n      <td>276</td>\n      <td>3</td>\n      <td>Comedy|Romance</td>\n      <td>35</td>\n      <td>0</td>\n      <td>1994</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Unique movie genres\n\nunique_words = set()\nfor genre in train['genre'].unique():\n    unique_words.update(genre.split('|'))\n\n    \n# Print genres\n\nprint(\"Unique genres:\", unique_words)\nprint(\"Number of genres:\", len(unique_words))","metadata":{"execution":{"iopub.status.busy":"2024-03-31T16:22:33.253165Z","iopub.execute_input":"2024-03-31T16:22:33.253626Z","iopub.status.idle":"2024-03-31T16:22:33.326687Z","shell.execute_reply.started":"2024-03-31T16:22:33.253580Z","shell.execute_reply":"2024-03-31T16:22:33.325358Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Unique genres: {'Film-Noir', 'Action', 'Adventure', 'Thriller', 'Fantasy', \"Children's\", 'Drama', 'Comedy', 'Mystery', 'Horror', 'Animation', 'Musical', 'Documentary', 'Western', 'Crime', 'War', 'Sci-Fi', 'Romance'}\nNumber of genres: 18\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Factorization Machine approach","metadata":{}},{"cell_type":"markdown","source":"Taking the notebook given in the Virtual Campus as a baseline, we modified it to match this problem.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","metadata":{"execution":{"iopub.status.busy":"2024-03-31T16:22:33.330630Z","iopub.execute_input":"2024-03-31T16:22:33.331589Z","iopub.status.idle":"2024-03-31T16:22:51.879057Z","shell.execute_reply.started":"2024-03-31T16:22:33.331539Z","shell.execute_reply":"2024-03-31T16:22:51.877586Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"2024-03-31 16:22:36.245948: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-31 16:22:36.246193: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-31 16:22:36.480534: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"def text2seq(text, n_genre):\n    \"\"\" using tokenizer to encoded the multi-level categorical feature\n    \"\"\"\n    tokenizer = Tokenizer(lower=True, split='|',filters='', num_words=n_genre)\n    tokenizer.fit_on_texts(text)\n    seq = tokenizer.texts_to_sequences(text)\n    seq = pad_sequences(seq, maxlen=3,padding='post')\n    return seq\n\nn_genre = 18\ntrain['genre'] = text2seq(train.genre.values, n_genre=n_genre+1).tolist()\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-31T16:22:51.880749Z","iopub.execute_input":"2024-03-31T16:22:51.881392Z","iopub.status.idle":"2024-03-31T16:23:03.372524Z","shell.execute_reply.started":"2024-03-31T16:22:51.881356Z","shell.execute_reply":"2024-03-31T16:23:03.371054Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   user_id                title  movie_id  rating      genre  age  sex  \\\n0     2592       Top Gun (1986)      1101       4  [3, 6, 0]   50    1   \n1     4318  12 Angry Men (1957)      1203       4  [2, 0, 0]   25    1   \n2     2756     Robocop 2 (1990)      2986       2  [3, 8, 5]   18    1   \n3     1706  Modern Times (1936)      3462       5  [1, 0, 0]   25    1   \n4     4813    Milk Money (1994)       276       3  [1, 6, 0]   35    0   \n\n   release_date  \n0          1986  \n1          1957  \n2          1990  \n3          1936  \n4          1994  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>title</th>\n      <th>movie_id</th>\n      <th>rating</th>\n      <th>genre</th>\n      <th>age</th>\n      <th>sex</th>\n      <th>release_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2592</td>\n      <td>Top Gun (1986)</td>\n      <td>1101</td>\n      <td>4</td>\n      <td>[3, 6, 0]</td>\n      <td>50</td>\n      <td>1</td>\n      <td>1986</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4318</td>\n      <td>12 Angry Men (1957)</td>\n      <td>1203</td>\n      <td>4</td>\n      <td>[2, 0, 0]</td>\n      <td>25</td>\n      <td>1</td>\n      <td>1957</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2756</td>\n      <td>Robocop 2 (1990)</td>\n      <td>2986</td>\n      <td>2</td>\n      <td>[3, 8, 5]</td>\n      <td>18</td>\n      <td>1</td>\n      <td>1990</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1706</td>\n      <td>Modern Times (1936)</td>\n      <td>3462</td>\n      <td>5</td>\n      <td>[1, 0, 0]</td>\n      <td>25</td>\n      <td>1</td>\n      <td>1936</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4813</td>\n      <td>Milk Money (1994)</td>\n      <td>276</td>\n      <td>3</td>\n      <td>[1, 6, 0]</td>\n      <td>35</td>\n      <td>0</td>\n      <td>1994</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Process the DataFrame to match the factorization machine format\n\nuser_ids = train[\"user_id\"].unique().tolist()\nuser2user_encoded = {x: i for i, x in enumerate(user_ids)}\nuserencoded2user = {i: x for i, x in enumerate(user_ids)}\n\nmovie_ids = train[\"movie_id\"].unique().tolist()\nmovie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}\nmovie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}\n\ntrain[\"user\"] = train[\"user_id\"].map(user2user_encoded)\ntrain[\"movie\"] = train[\"movie_id\"].map(movie2movie_encoded)\n\nnum_users = len(user2user_encoded)\nnum_movies = len(movie_encoded2movie)\n\ntrain[\"rating\"] = train[\"rating\"].values.astype(np.float32)\n\n\n# min and max ratings will be used to normalize the ratings later\n\nmin_rating = min(train[\"rating\"])\nmax_rating = max(train[\"rating\"])\n\nprint(\n    \"Number of users: {}, Number of Movies: {}, Min rating: {}, Max rating: {}\".format(\n        num_users, num_movies, min_rating, max_rating\n    )\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T16:23:03.373861Z","iopub.execute_input":"2024-03-31T16:23:03.374252Z","iopub.status.idle":"2024-03-31T16:23:03.599526Z","shell.execute_reply.started":"2024-03-31T16:23:03.374220Z","shell.execute_reply":"2024-03-31T16:23:03.598195Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Number of users: 6040, Number of Movies: 3680, Min rating: 1.0, Max rating: 5.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# Show the process result\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-31T16:23:03.601389Z","iopub.execute_input":"2024-03-31T16:23:03.601745Z","iopub.status.idle":"2024-03-31T16:23:03.618269Z","shell.execute_reply.started":"2024-03-31T16:23:03.601718Z","shell.execute_reply":"2024-03-31T16:23:03.617025Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"   user_id                title  movie_id  rating      genre  age  sex  \\\n0     2592       Top Gun (1986)      1101     4.0  [3, 6, 0]   50    1   \n1     4318  12 Angry Men (1957)      1203     4.0  [2, 0, 0]   25    1   \n2     2756     Robocop 2 (1990)      2986     2.0  [3, 8, 5]   18    1   \n3     1706  Modern Times (1936)      3462     5.0  [1, 0, 0]   25    1   \n4     4813    Milk Money (1994)       276     3.0  [1, 6, 0]   35    0   \n\n   release_date  user  movie  \n0          1986     0      0  \n1          1957     1      1  \n2          1990     2      2  \n3          1936     3      3  \n4          1994     4      4  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>title</th>\n      <th>movie_id</th>\n      <th>rating</th>\n      <th>genre</th>\n      <th>age</th>\n      <th>sex</th>\n      <th>release_date</th>\n      <th>user</th>\n      <th>movie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2592</td>\n      <td>Top Gun (1986)</td>\n      <td>1101</td>\n      <td>4.0</td>\n      <td>[3, 6, 0]</td>\n      <td>50</td>\n      <td>1</td>\n      <td>1986</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4318</td>\n      <td>12 Angry Men (1957)</td>\n      <td>1203</td>\n      <td>4.0</td>\n      <td>[2, 0, 0]</td>\n      <td>25</td>\n      <td>1</td>\n      <td>1957</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2756</td>\n      <td>Robocop 2 (1990)</td>\n      <td>2986</td>\n      <td>2.0</td>\n      <td>[3, 8, 5]</td>\n      <td>18</td>\n      <td>1</td>\n      <td>1990</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1706</td>\n      <td>Modern Times (1936)</td>\n      <td>3462</td>\n      <td>5.0</td>\n      <td>[1, 0, 0]</td>\n      <td>25</td>\n      <td>1</td>\n      <td>1936</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4813</td>\n      <td>Milk Money (1994)</td>\n      <td>276</td>\n      <td>3.0</td>\n      <td>[1, 6, 0]</td>\n      <td>35</td>\n      <td>0</td>\n      <td>1994</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"We also tried several approaches to perform the train-test split, such as user or item based. Nonetheless, neither of them improved the performance, so we decided to perform the usual 80-20 split.","metadata":{}},{"cell_type":"code","source":"# Perform train-test split\n\nfrom sklearn.model_selection import train_test_split\n\ntrai, val = train_test_split(train, test_size=0.2, random_state=7)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T16:23:03.623290Z","iopub.execute_input":"2024-03-31T16:23:03.624012Z","iopub.status.idle":"2024-03-31T16:23:04.610669Z","shell.execute_reply.started":"2024-03-31T16:23:03.623968Z","shell.execute_reply":"2024-03-31T16:23:04.608816Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import tensorflow.keras.backend as K\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import *\n\ndef define_input_layers():\n    # numerical features\n    age_input = Input((1,), name = 'input_age') #age\n    num_inputs = [age_input]\n    \n    # single level categorical features\n    uid_input = Input((1,), name = 'input_uid') #user_id\n    mid_input = Input((1,), name = 'input_mid') #movie_id\n    sex_input = Input((1,), name = 'input_sex') #sex\n    cat_sl_inputs = [uid_input, mid_input, sex_input]\n\n    # multi level categorical features (with 3 genres at most)\n    genre_input = Input((3,), name = 'input_genre')\n    cat_ml_inputs = [genre_input]\n\n    inputs = num_inputs + cat_sl_inputs + cat_ml_inputs\n    \n    return inputs\n\ninputs = define_input_layers()","metadata":{"execution":{"iopub.status.busy":"2024-03-31T16:23:04.612257Z","iopub.execute_input":"2024-03-31T16:23:04.612904Z","iopub.status.idle":"2024-03-31T16:23:04.632718Z","shell.execute_reply.started":"2024-03-31T16:23:04.612863Z","shell.execute_reply":"2024-03-31T16:23:04.631362Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def Tensor_Mean_Pooling(name = 'mean_pooling', keepdims = False):\n    return Lambda(lambda x: K.mean(x, axis = 1, keepdims=keepdims), name = name, mask=lambda inputs, mask: None)\n\ndef fm_1d(inputs, n_uid, n_mid, n_sex, n_genre):\n    \n    # user feat3 + user embedding + movie embedding + genre embedding\n    age_input, uid_input, mid_input, sex_input, genre_input = inputs\n    \n    # all tensors are reshape to (None, 1)\n    num_dense_1d = [Dense(1, name = 'num_dense_1d_age')(age_input)]\n    cat_sl_embed_1d = [Embedding(n_uid + 1, 1, name = 'cat_embed_1d_uid')(uid_input),\n                       Embedding(n_mid + 1, 1, name = 'cat_embed_1d_mid')(mid_input),\n                       Embedding(n_sex + 1, 1, name = 'cat_embed_1d_sex')(sex_input)]\n    cat_ml_embed_1d = [Embedding(n_genre + 1, 1, mask_zero=True, name = 'cat_embed_1d_genre')(genre_input)]\n\n    cat_sl_embed_1d = [Reshape((1,))(i) for i in cat_sl_embed_1d]\n    cat_ml_embed_1d = [Tensor_Mean_Pooling(name = 'embed_1d_mean')(i) for i in cat_ml_embed_1d]\n    \n    # add all tensors\n    y_fm_1d = Add(name = 'fm_1d_output')(num_dense_1d + cat_sl_embed_1d + cat_ml_embed_1d)\n    \n    return y_fm_1d\n\ny_1d = fm_1d(inputs, 10, 10, 2, 10)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T16:23:04.634838Z","iopub.execute_input":"2024-03-31T16:23:04.635423Z","iopub.status.idle":"2024-03-31T16:23:04.754907Z","shell.execute_reply.started":"2024-03-31T16:23:04.635373Z","shell.execute_reply":"2024-03-31T16:23:04.753860Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def fm_2d(inputs, n_uid, n_mid, n_sex, n_genre, k):\n    \n    age_input, uid_input, mid_input, sex_input, genre_input = inputs\n    \n    num_dense_2d = [Dense(k, name = 'num_dense_2d_age')(age_input)] # shape (None, k)\n    num_dense_2d = [Reshape((1,k))(i) for i in num_dense_2d] # shape (None, 1, k)\n\n    cat_sl_embed_2d = [Embedding(n_uid + 1, k, name = 'cat_embed_2d_uid')(uid_input), \n                       Embedding(n_mid + 1, k, name = 'cat_embed_2d_mid')(mid_input),\n                       Embedding(n_sex + 1, k, name = 'cat_embed_2d_sex')(sex_input)] # shape (None, 1, k)\n    \n    cat_ml_embed_2d = [Embedding(n_genre + 1, k, name = 'cat_embed_2d_genre')(genre_input)] # shape (None, 3, k)\n    cat_ml_embed_2d = [Tensor_Mean_Pooling(name = 'cat_embed_2d_genre_mean', keepdims=True)(i) for i in cat_ml_embed_2d] # shape (None, 1, k)\n\n    # concatenate all 2d embed layers => (None, ?, k)\n    embed_2d = Concatenate(axis=1, name = 'concat_embed_2d')(num_dense_2d + cat_sl_embed_2d + cat_ml_embed_2d)\n\n    # calcuate the interactions by simplication\n    # sum of (x1*x2) = sum of (0.5*[(xi)^2 - (xi^2)])\n    tensor_sum = Lambda(lambda x: K.sum(x, axis = 1), name = 'sum_of_tensors')\n    tensor_square = Lambda(lambda x: K.square(x), name = 'square_of_tensors')\n\n    sum_of_embed = tensor_sum(embed_2d)\n    square_of_embed = tensor_square(embed_2d)\n\n    square_of_sum = Multiply()([sum_of_embed, sum_of_embed])\n    sum_of_square = tensor_sum(square_of_embed)\n\n    sub = Subtract()([square_of_sum, sum_of_square])\n    sub = Lambda(lambda x: x*0.5)(sub)\n    y_fm_2d = Reshape((1,), name = 'fm_2d_output')(tensor_sum(sub))\n    \n    return y_fm_2d, embed_2d\n\ny_fm2_d, embed_2d = fm_2d(inputs, 10, 10, 2, 10, 5)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T16:23:04.756214Z","iopub.execute_input":"2024-03-31T16:23:04.757255Z","iopub.status.idle":"2024-03-31T16:23:04.848887Z","shell.execute_reply.started":"2024-03-31T16:23:04.757214Z","shell.execute_reply":"2024-03-31T16:23:04.847507Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def fm_model(n_uid, n_mid, n_sex, n_genre, k, dnn_dr):\n    \n    inputs = define_input_layers()\n    \n    y_fm_1d = fm_1d(inputs, n_uid, n_mid, n_sex, n_genre)\n    y_fm_2d, embed_2d = fm_2d(inputs, n_uid, n_mid, n_sex, n_genre, k)\n    \n    # combine deep and fm parts\n    y = Concatenate()([y_fm_1d, y_fm_2d])\n    y = Dense(1, name = 'fm_output')(y)\n    \n    fm_model_1d = Model(inputs, y_fm_1d)\n    fm_model_2d = Model(inputs, y_fm_2d)\n    fm_model = Model(inputs, y)\n    \n    return fm_model_1d, fm_model_2d, fm_model","metadata":{"execution":{"iopub.status.busy":"2024-03-31T16:23:04.850581Z","iopub.execute_input":"2024-03-31T16:23:04.851044Z","iopub.status.idle":"2024-03-31T16:23:04.858828Z","shell.execute_reply.started":"2024-03-31T16:23:04.851007Z","shell.execute_reply":"2024-03-31T16:23:04.857616Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"params = {\n    'n_uid': train.user.nunique(),\n    'n_mid': train.movie.nunique(),\n    'n_sex': 2,\n    'n_genre': 18,\n    'k': 20,\n    'dnn_dr': 0.5\n}\n\nfm_model_1d, fm_model_2d, fm_model = fm_model(**params)\n\nparams","metadata":{"execution":{"iopub.status.busy":"2024-03-31T16:23:04.860485Z","iopub.execute_input":"2024-03-31T16:23:04.861884Z","iopub.status.idle":"2024-03-31T16:23:05.052185Z","shell.execute_reply.started":"2024-03-31T16:23:04.861834Z","shell.execute_reply":"2024-03-31T16:23:05.050458Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'n_uid': 6040,\n 'n_mid': 3680,\n 'n_sex': 2,\n 'n_genre': 18,\n 'k': 20,\n 'dnn_dr': 0.5}"},"metadata":{}}]},{"cell_type":"code","source":"def df2xy(ratings):\n    x = [ratings.age.values,\n         ratings.user.values, \n         ratings.movie.values,\n         ratings.sex.values,\n         np.concatenate(ratings.genre.values).reshape(-1,3)]\n    y = ratings.rating.values\n    return x,y\n\ntrain_x, train_y = df2xy(trai)\nvalid_x, valid_y = df2xy(val)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T16:23:05.053684Z","iopub.execute_input":"2024-03-31T16:23:05.054594Z","iopub.status.idle":"2024-03-31T16:23:06.315120Z","shell.execute_reply.started":"2024-03-31T16:23:05.054554Z","shell.execute_reply":"2024-03-31T16:23:06.313953Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import  EarlyStopping, ModelCheckpoint\n\n# train model\n\nfm_model.compile(\n    loss=tf.keras.losses.MeanSquaredError(), optimizer=keras.optimizers.Adam(learning_rate=0.0001)\n)\nearly_stop = EarlyStopping(monitor='val_loss', patience=3)\ncallbacks=[early_stop]\ntrain_history = fm_model.fit(train_x, train_y, \n                                  epochs=50, batch_size=4096, \n                                  validation_data=(valid_x, valid_y),\n                                  callbacks = callbacks, \n                                 verbose=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T16:23:06.316925Z","iopub.execute_input":"2024-03-31T16:23:06.317344Z","iopub.status.idle":"2024-03-31T16:24:52.461575Z","shell.execute_reply.started":"2024-03-31T16:23:06.317312Z","shell.execute_reply":"2024-03-31T16:24:52.460789Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 7.3169 - val_loss: 2.0338\nEpoch 2/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 1.7322 - val_loss: 1.3186\nEpoch 3/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 1.2419 - val_loss: 1.1652\nEpoch 4/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 1.1193 - val_loss: 1.1051\nEpoch 5/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 1.0736 - val_loss: 1.0709\nEpoch 6/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 1.0440 - val_loss: 1.0444\nEpoch 7/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 1.0186 - val_loss: 1.0206\nEpoch 8/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.9948 - val_loss: 0.9985\nEpoch 9/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.9755 - val_loss: 0.9799\nEpoch 10/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.9576 - val_loss: 0.9631\nEpoch 11/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.9414 - val_loss: 0.9489\nEpoch 12/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.9261 - val_loss: 0.9355\nEpoch 13/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.9161 - val_loss: 0.9236\nEpoch 14/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.9045 - val_loss: 0.9156\nEpoch 15/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.8972 - val_loss: 0.9079\nEpoch 16/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.8871 - val_loss: 0.9003\nEpoch 17/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.8817 - val_loss: 0.8950\nEpoch 18/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.8792 - val_loss: 0.8919\nEpoch 19/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.8747 - val_loss: 0.8882\nEpoch 20/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.8733 - val_loss: 0.8856\nEpoch 21/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.8693 - val_loss: 0.8819\nEpoch 22/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.8680 - val_loss: 0.8811\nEpoch 23/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.8627 - val_loss: 0.8798\nEpoch 24/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.8629 - val_loss: 0.8783\nEpoch 25/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.8610 - val_loss: 0.8769\nEpoch 26/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.8629 - val_loss: 0.8759\nEpoch 27/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.8592 - val_loss: 0.8756\nEpoch 28/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.8563 - val_loss: 0.8739\nEpoch 29/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.8581 - val_loss: 0.8724\nEpoch 30/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.8552 - val_loss: 0.8722\nEpoch 31/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.8535 - val_loss: 0.8713\nEpoch 32/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.8541 - val_loss: 0.8714\nEpoch 33/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.8548 - val_loss: 0.8702\nEpoch 34/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.8552 - val_loss: 0.8698\nEpoch 35/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.8523 - val_loss: 0.8694\nEpoch 36/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.8531 - val_loss: 0.8689\nEpoch 37/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.8512 - val_loss: 0.8691\nEpoch 38/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.8523 - val_loss: 0.8678\nEpoch 39/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.8497 - val_loss: 0.8669\nEpoch 40/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.8524 - val_loss: 0.8691\nEpoch 41/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.8505 - val_loss: 0.8658\nEpoch 42/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.8516 - val_loss: 0.8658\nEpoch 43/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.8531 - val_loss: 0.8658\nEpoch 44/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.8462 - val_loss: 0.8644\nEpoch 45/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.8459 - val_loss: 0.8642\nEpoch 46/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.8499 - val_loss: 0.8647\nEpoch 47/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.8480 - val_loss: 0.8630\nEpoch 48/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.8447 - val_loss: 0.8624\nEpoch 49/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.8466 - val_loss: 0.8639\nEpoch 50/50\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.8450 - val_loss: 0.8627\n","output_type":"stream"}]},{"cell_type":"markdown","source":"After training our neural network, we must create a DataFrame with all user and unseen movies pairs.","metadata":{}},{"cell_type":"code","source":"# Take the ids of both users and movies without duplicates\n\nusers = train['user'].unique()\nmovies = train['movie'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-03-31T16:24:52.465741Z","iopub.execute_input":"2024-03-31T16:24:52.466060Z","iopub.status.idle":"2024-03-31T16:24:52.482700Z","shell.execute_reply.started":"2024-03-31T16:24:52.466034Z","shell.execute_reply":"2024-03-31T16:24:52.481471Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Take features of both users and movies\n\nusers_feat = train[['user', 'sex', 'age']]\nusers_feat = users_feat.drop_duplicates(subset='user')\nusers_feat.set_index('user', inplace=True)\n\nmovie_feat = train[['movie', 'title', 'genre', 'release_date']]\nmovie_feat = movie_feat.drop_duplicates(subset='movie')\nmovie_feat.set_index('movie', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T16:24:52.486097Z","iopub.execute_input":"2024-03-31T16:24:52.486505Z","iopub.status.idle":"2024-03-31T16:24:52.563288Z","shell.execute_reply.started":"2024-03-31T16:24:52.486477Z","shell.execute_reply":"2024-03-31T16:24:52.562325Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def df2x(ratings):\n    x = [ratings.age.values,\n         ratings.user.values, \n         ratings.movie.values, \n         ratings.sex.values,\n         np.concatenate(ratings.genre.values).reshape(-1,3)]\n    return x","metadata":{"execution":{"iopub.status.busy":"2024-03-31T16:24:52.564417Z","iopub.execute_input":"2024-03-31T16:24:52.565219Z","iopub.status.idle":"2024-03-31T16:24:52.571402Z","shell.execute_reply.started":"2024-03-31T16:24:52.565187Z","shell.execute_reply":"2024-03-31T16:24:52.569923Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"We mapped the movies in our training, so we also have to apply it to the test set.","metadata":{}},{"cell_type":"code","source":"# Create a DataFrame with the movies each user has not seen\n\nresults = {}\ncont = 0\n\nfor user in users:\n    # Log after 500 iterations\n    if cont % 500 == 0:\n        print(cont)\n        \n    # Update the counter\n    cont += 1\n    \n    # Create the list of unseen films for each user and take its length\n    missing_films = set(movies) - set(train[train['user'] == user]['movie'])\n    n = len(missing_films)\n    \n    # Take the user's features\n    user_sex = users_feat['sex'][user]\n    user_age = users_feat['age'][user]\n    genre_list = [movie_feat['genre'][movie] for movie in missing_films]\n    release_list = [movie_feat['release_date'][movie] for movie in missing_films]\n\n    # Create the user DataFrame\n    df = pd.DataFrame({\n        'user': n * [user],\n        'movie': list(missing_films),\n        'sex': n * [user_sex],\n        'age': n * [user_age],\n        'genre': genre_list,\n        'release_date': release_list\n    })\n\n    # Make the predictions for the current user and store the top 25 movies\n    test_x = df2x(df)\n    predictions = fm_model.predict(test_x,verbose=0)\n    preds = [item for sublist in predictions for item in sublist]\n    sort = np.argsort(preds)[::-1][:25]\n    top25 = [list(missing_films)[i] for i in sort]\n    top25_mapped = [movie_encoded2movie[item] for item in top25]\n    results[userencoded2user[user]] = top25_mapped\n    \n    ### To check if we did the transformation properly\n    for t in top25_mapped:\n        if t not in train['movie_id']:\n            print ('Not in train')","metadata":{"execution":{"iopub.status.busy":"2024-03-31T16:24:52.572782Z","iopub.execute_input":"2024-03-31T16:24:52.573190Z","iopub.status.idle":"2024-03-31T17:09:44.644044Z","shell.execute_reply.started":"2024-03-31T16:24:52.573158Z","shell.execute_reply":"2024-03-31T17:09:44.642863Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"0\n500\n1000\n1500\n2000\n2500\n3000\n3500\n4000\n4500\n5000\n5500\n6000\n","output_type":"stream"}]},{"cell_type":"code","source":"# Show how the solution should be stored\n\ntest_example = pd.read_csv('/kaggle/input/recsysmasterfds-2024/kaggle_baseline.csv')","metadata":{"execution":{"iopub.status.busy":"2024-03-31T17:09:44.645743Z","iopub.execute_input":"2024-03-31T17:09:44.646055Z","iopub.status.idle":"2024-03-31T17:09:44.686678Z","shell.execute_reply.started":"2024-03-31T17:09:44.646029Z","shell.execute_reply":"2024-03-31T17:09:44.685697Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"Finally, we store our results in a .csv output file.","metadata":{}},{"cell_type":"code","source":"# Convert our results dictionary into the corresponding format\n\nimport csv\n\n# open the file in the write mode\nwith open('solution.csv', 'w', encoding='UTF8') as f:\n    \n    # create the csv writer\n    writer = csv.writer(f)\n    \n    # write the headers of both columns\n    writer.writerow(['user_id', 'prediction'])\n    \n    # write a row for each user\n    for user_id in test_example.user_id.unique():\n        relevant_items = results[user_id]\n        list_relevants = ' '.join([str(elem) for elem in relevant_items])\n        writer.writerow([str(user_id),list_relevants])","metadata":{"execution":{"iopub.status.busy":"2024-03-31T17:09:44.688271Z","iopub.execute_input":"2024-03-31T17:09:44.688733Z","iopub.status.idle":"2024-03-31T17:09:44.759598Z","shell.execute_reply.started":"2024-03-31T17:09:44.688691Z","shell.execute_reply":"2024-03-31T17:09:44.758720Z"},"trusted":true},"execution_count":23,"outputs":[]}]}